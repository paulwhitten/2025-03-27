<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>reveal.js</title>

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/white.css" id="theme">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css" id="highlight-theme">

		<!-- remove uppercase text transform from headings -->
		<style>
			.reveal h1, .reveal h2, .reveal h3, .reveal h4, .reveal h5, .reveal h6, .reveal h7 {
				text-transform: none;
			}
			.smallest {
				font-size: 15px;
			}
			.smaller {
				font-size: 18px;
			}
			.medium {
				font-size: 25px;
			}
			.mid {
				font-size: 30px;
			}
			.large {
				font-size: 35px;
			}
			.realbig {
				font-size: 50px;
			}
			.huge {
				font-size: 60px;
			}
			table, td, th, img {
				border: 2px solid white;
				border-collapse: collapse;
				text-align: left;
  				vertical-align: middle;
				padding: 0px;
				border-spacing: 0px;
			}
			.container{
    			display: flex;
			}
			.col{
    			flex: 1;
			}

			table {
			border:2px solid black;
			border-collapse: collapse;
			}
			th {
			border:2px solid black;
			border-collapse: collapse;
			}
			td {
			border:2px solid black;
			text-align: center;
			border-collapse: collapse;
			}
		</style>

	</head>
	<body>
		<div class="reveal">
			<div class="slides">

				<!-- title slide -->
				<section>
					<h1>
						Explainable AI Architectures:
					</h1>
					<h2>
						Methods, Applications, Examples, and Results
					</h2>

					<p class="large"><a href="https:case.edu">Case Western Reserve University</a></p>
				
					<p class="large"><a href="https://engineering.case.edu/">Case School of Engineering</a></p>

					<p class="large"><a href="https://engineering.case.edu/electrical-computer-and-systems-engineering">Electrical, Computer, and Systems Engineering</a></p>
					
					<div class="large"><a href=mailto:pcw@case.edu>Paul Whitten</a>
					
					<p class="large"><a href="https://paulwhitten.github.io/xai_arch_presentation/">2025-03-27</a></p>

				</section>

				<section>
					<h1>Outline</h1>
					<ul class="huge">
						<li>Introduction</li>
						<li>Problem</li>
						<li>Contributions</li>
						<li>Background and Related Work</li>
						<li>Property-Based Explainable (PBE) Method</li>
						<ul>
							<li>PBE Handwritten Character Results</li>
							<li>PBE Hardware Trojan Results</li>
						</ul>
						<li>Case-Based Explainable (CBE) Method</li>
						<ul>
							<li>CBE Handwritten Character Results</li>
							<li>CBE Hardware Trojan Character Results</li>
						</ul>
						<li>Conclusion</li>
						<li>Future Work</li>
					</ul>

					<aside class="notes">

						<p>This is an outline of the presentation</p>
						<p>First a brief introduction</p>
						<p>Followed by a problem statement</p>
						<p>Go over contributions</p>
						<p>Brief discussion of background and related work</p>
						<p>Discuss two explainable methods property based and case-based</p>
						<p>The methods are applied to two diverse applications</p>
						<p>Talk about conclusions</p>
						<p>Discuss future work</p>
					</aside>
				</section>

				<section>
					<h1>Introduction</h1>
					<ul class="huge">
						<li>Artificial Intelligence (AI) and Machine Learning (ML) used widely<br>Applications: Business, Medicine, Transportation</li>
						<li>Lack of trust in AI - models are often an opaque box</li>
						<li>Many AI systems cannot effectively explain or justify decisions</li>
						<li>Explainable AI (XAI)</li>
					</ul>
					<aside class="notes">
						<p>
							AI and in particular ML are used widely in business, medicine, technology, transportation.
							Performance of ML can surpass human performance.
						</p>
						<p>There is a lack of trust in AI as many models act as a black box.</p>
						<p>ML cannot justify or explain decisions</p>
						<p>
							In recent years XAI has gained in popularity. There
							has been extensive research on XAI and GDPR
							discussions arguing a right to explanations.
						</p>
					</aside>
				</section>

				<section>
					<h1>Problem</h1>
					<ul class="huge">
						<li>Neural Networks cannot explain their inferences</li>
						<li>Therefore, there is a lack of trust in these systems</li>
						<li>XAI systems are an attempt to explain the inference by a trained NN and increase trust in ML systems</li>
						<li>An explanation should be in plain terms</li>
					</ul>

					<aside class="notes">
						<p>Neural networks and many other Machine Learning models cannot explain inferences that they make</p>
						<p>This brings about a lack of trust in </p>
						<p>XAI is an attempt to explain inference by trained neural networks and increase trust in ML systems.</p>
						<p>User should be able to interpret the explanation</p>
					</aside>
				</section>

				<section>
					<h2>Comparison</h2>
					<img src="./images/traditional_ml_xai_future.svg">

					<aside class="notes">
						<p>Traditional AI at the top of the diagram shows the traditional ML AI flow</p>
						<p>A system is trained to provide a decision or recommendation</p>
						<p>A user is left with important unanswered questions causing a lack of trust.</p>
						<p>The bottom XAI diagram is the hope for future XAI systems</p>
						<p>An explainable model and explainable interface help to answer questions.</p>
						<p>
							The user is presented with explanations and data to assist rather than
							only a decision in traditional AI systems.
						</p>
					</aside>
				</section>

				<section>
					<div class="container">
						<div class="col" style="border-right:1px solid #000;height:1080px">

							<h2>Contributions</h2>
							<br>
							<ul class="realbig">
								<li>PBE Method and Architecture</li>
								<li>CBE Method and Architecture</li>
								<li>Explainability metric - $Ex(c)$</li>
								<li>Combining explainability with unexplainability</li>
								<li>Metric for Effectiveness of a model - $E(j, c)$</li>
								<li>A new metric for model performance - $E_{PARS}$</li>
								<li>Communicating when a model can fail - FDR</li>
								<li>Correspondence metric - $Corr$</li>
							</ul>
						</div>


					<div class="col">
						<img src="./images/method-intro-dot.svg" height="1080">
					</div>

					<aside class="notes">
						<p>The diagram on the right shows a concept map of this work.</p>
						<p>Listed on the left are some contributions</p>
						<p>Two methods and explainable architectures are presented. Property and case based.</p>
						<p>Each method has strengths with type of data and in applying the methods</p>
						<p>Metrics for explainability of property based</p>
						<p>Combining explainable components with unexplainable to improve performance</p>
						<p>Metric to gauge the effectiveness of a model, j, for a particular class, c</p>
						<p>The EPARS metric for such effectiveness that is resilient to data imbalance</p>
						<p>Using data in the knowledgbase from training and testing such as the confusion matrix to show when a system may fail using the false discovery rate.</p>
						<p>A correspondence metric used in the CBE to show when the training cases agree.</p>
					</aside>
				</section>

					<section>
						<h1>Publications</h1>
						<ul class="realbig">
							<li>Four IEEE Conference papers and presentations</li>
							<ul>
								<li>2021 - <a href="https://doi.org/10.1109/NAECON49338.2021.9696413">Explainable Artificial Intelligence Methodology for Handwritten Applications</a></li>
								<li>2023 - <a href="https://doi.org/10.1109/CCWC57344.2023.10099288">Explainable Neural Network Recognition of Handwritten Characters</a></li>
								<li>2024 - <a href="https://doi.org/10.1109/ICMI60790.2024.10586116">An AI Architecture with the Capability to Explain Recognition Results</a></li>
								<li>2024 - <a href="https://doi.org/10.1109/NAECON61878.2024.10670684">An AI Architecture with the Capability to Classify and Explain Hardware Trojans</a></li>
								<li>Working papers for journal submission</li>
							</ul>
						</ul>
						<aside class="notes">
							<p></p>
						</aside>
					</section>
					
					<section>
						<h1>Background and Related Work</h1>
						<br>
						
					</section>

					<section>

						<h2>AI Taxonomy - Capability and Functionality</h2>

 						<img src="./images/ai_taxonomy.svg" height="700">

						<aside class="notes">
							<p>This diagram presents a taxonomy of AI based on capability and function</p>
							<p>Capabilities are weak,  strong, and super</p>
							<p>Weak can perform purpose built tasks</p>
							<p>The areas under weak that are shaded are the type of AI covered in this research</p>
							<p>General can perform at or near human levels</p>
							<p>Super can perform above human levels of cognition</p>
							<p>Among the weak or also known as Narrow AI there is additional functionality based on reactive or limited memory functionality</p>
							<p>Reactive is least can perform singular tasks state is immediate no data saved - chess playing, classification</p>
							<p>Limited memory has more than immediate state save data from past - LLM, Generative AI, Autonomous vehicle</p>
							<p>Theory of mind is considering relation to others and how others feel</p>
							<p>Self aware elements of consciousness and awareness of its own existence.</p>
						</aside>
					</section>

					<section>

						<h2>AI Taxonomy - Algorithms and Architectures</h2>

						<img src="./images/ai_taxonomy_algorithms.svg" height="800">

						<aside class="notes">
							<p>AI can further be decomposed by algorithm or architecture type</p>
							<p>Symbolic AI - expert systems and agents</p>
							<p>Learning systems - Supervised, Unsupervised, Reinforcement</p>
							<p>Supervised learning involves adding feedback to the learning process</p>
							<p>Unsupervised uses no feedback</p>
							<p>Reinforcement learning involves providing a notion of rewards if positive or punishments if negative. </p>
							<p>This work primarily focuses on Supervised learning methods tat you see highlighted in the taxonomy.</p>
						</aside>
					</section>

					<section>
						<h1>Multi-layer Feed Forward Neural Network</h1>
						<img src="./images/multi_layer_ff_nn.svg" height="700">

						<p>Inference but no explanation</p>
						
						<aside class="notes">
							<p>This is a multi-layer neural network</p>
							<p>Input comes in at the left</p>
							<p>Output is at the right</p>
							<p>Fully connected layers.  Each neuron connected to neurons in the next layer.</p>
							<p>A network like this may perform simple binary classification</p>
							<p>Hidden layers are not connected to inputs or outputs</p>
							<p>This neural network and others like it can perform inference but provide no explanation</p>
						</aside>
					</section>

					<section>
						<h1>1995 - LeNet-5 CNN Neural Network</h1>
						<img src="./images/LeNet-5_architecture.svg.png">

						<p>Major improvement in inference performance but still no explanation</p>

						<aside class="notes">
							<p>The neural network architecture depicted here is LeNet-5</p>
							<p>It is a convolutional neural network that uses local connections in convolutionional layers rather than fully connected</p>
							<p>Like convolving a kernel across an image</p>
							<p>Kernels are designed to detect particular feature in the image and activate a neuron in subsequent layers</p>
							<p>At the time this architecture outperformed other models but still could not explain. </p>
						</aside>
					</section>

					<section>
						<h1>2015 - ResNet</h1>
						<img src="./images/resnet.svg" height="800">

						<p>Outstanding performance but cannot explain results</p>

						<aside class="notes">
							<p>With growth of deep learning in 2015 the depth of neural networks was increasing to 20 - 30 layers.</p>
							<p>Learning at this depth suffered from a degradation of accuracy as networks grew deeper. Due to the vanishing gradient problem.</p>
							<p>Deep residual learning (ResNet) introduced skip layers to reintroduce the input at subsequent layers to overcome this problem</p>
							<p>Deep Residual networks were able to be constructed to depths of 50 to over 100 layers</p>
							<p>ResNet was constructed for image processing and won the ImageNet visual recognition challenge</p>
							<p>Despite the outstanding results, ResNet does not explain</p>
						</aside>
					</section>

					<section>
						<h2>
							XAI Research
						</h2>
						<ul class="realbig">
							<li>1999 - Case-Based Explanation of Non-Case-Based Learning Methods - Caruana et al.</li>
							<li>2018 - Explainable neural networks based on additive index models - Vaughan et al.</li>
						</ul>

						<img src="./images/xNNarch.png" height="500">

						<aside class="notes">
							<p>In this 1999 work, medical researchers pose using case based explanations.</p>
							<p>Used activation values of hidden units in the model during training to represent a point in space. New samples with like points in space were considered like cases</p>
							<p>Vaughan's 2018 work involved projecting inputs to distinct, layered, and unconnected NNs. A layer then
								combines the outputs of the distinct NNs to perform a prediction</p>
							<p>
								Using such an architecture, the work showed that the distinct NNs could learn functions h1(x) through hk(x) that when combined
								gave the desired function that modeled the desired f(x)
							</p>
						</aside>
					</section>

					<section>
						<h2>XAI Research - LIME</h2>

						<p class="realbig">2016 - Why should I Trust you - Marco Tulio Ribeiro et al. - LIME</p>
						<hr>
						<p class="realbig">
							LIME superpixel mask for classification as a Bernese mountain dog
						</p>
						<img src="./images/lime_image1.png" height="300"> <img src="./images/lime_image1_mask.png" height="300">
						<hr>
						<p class="realbig">LIME on Handwritten Digits</p>
						<div class=container>
							<div class="col" style="border-right:1px solid #000;height:90px">
								<img src="./images/lime/orig-0.png" height="80">
								<img src="./images/lime/pos-neg-0.png" height="80">
							</div>
							<div class="col" style="border-right:1px solid #000;height:90px">
								<img src="./images/lime/orig-2.png" height="80">
								<img src="./images/lime/pos-neg-2.png" height="80">
							</div>
							<div class="col" style="border-right:1px solid #000;height:90px">
								<img src="./images/lime/orig-14.png" height="80">
								<img src="./images/lime/pos-neg-14.png" height="80">
							</div>
							<div class="col" style="border-right:1px solid #000;height:90px">
								<img src="./images/lime/orig-4.png" height="80">
								<img src="./images/lime/pos-neg-4.png" height="80">
							</div>
							<div class="col" style="border-right:1px solid #000;height:90px">
								<img src="./images/lime/orig-6.png" height="80">
								<img src="./images/lime/pos-neg-6.png" height="80">
							</div>
							<div class="col">
								<img src="./images/lime/orig-19.png" height="80">
								<img src="./images/lime/pos-neg-19.png" height="80">
							</div>
						</div>
						<hr>
						<div class=container>
							<div class="col" style="border-right:1px solid #000;height:90px">
								<img src="./images/lime/orig-7.png" height="80">
								<img src="./images/lime/pos-neg-7.png" height="80">
							</div>
							<div class="col" style="border-right:1px solid #000;height:90px">
								<img src="./images/lime/orig-9.png" height="80">
								<img src="./images/lime/pos-neg-9.png" height="80">
							</div>
							<div class="col" style="border-right:1px solid #000;height:90px">
								<img src="./images/lime/orig-12.png" height="80">
								<img src="./images/lime/pos-neg-12.png" height="80">
							</div>
							<div class="col" style="border-right:1px solid #000;height:90px">
								<img src="./images/lime/orig-16.png" height="80">
								<img src="./images/lime/pos-neg-16.png" height="80">
							</div>
							<div class="col" style="border-right:1px solid #000;height:90px">
								<img src="./images/lime/orig-8.png" height="80">
								<img src="./images/lime/pos-neg-8.png" height="80">
							</div>
							<div class="col">
								<img src="./images/lime/orig-15.png" height="80">
								<img src="./images/lime/pos-neg-15.png" height="80">
							</div>
						</div>

						<aside class="notes">
							<p>LIME is an important work for local interpretable model agnostic explanations.</p>
							<p>
								In LIME an image is divided into superpixels and for an input sample and prediction, the data is perturbed
								to ascertain the superpixels important for the classification.  They change superpixels that alter the prediction.
							</p>
							<p>
								Example of the important superpixels for detecting an image as a Bernese Mountain dog
							</p>
							<p>
								Examples of LIME on handwritten digits.  These
								are from the first 20 samples in the MNIST test set. We have
								12 image pairs that show the original image and
								then the important superpixels highlighted in
								pink
							</p>
							<p>
								In some cases the entire image was important.
								Note the inconsistency in what is important for
								the same digit class. In some like digits
								different regions were important.
							</p>
							<p>These are not the types of explanations that would build trust.</p>
						</aside>

					</section>

					<section>
						<h2>XAI Research - Continued</h2>
						<ul class="realbig">
							<li>2017 - A Unified Approach to Interpreting Model Predictions Lundberg et al. - SHAP</li>
							<img src="./images/shap_MNIST_Example_3_0.png">
						</ul>
						<aside class="notes">
							<p>Shapley Additive Explanations - SHAP in 2018 Lundberg.</p>
							<p>This method uses Shapley values from cooperative game theory as measures of marginal feature importance.</p>
							<p>The figure shows five samples in rows with the the original image on the left</p>
							<p>The ten decimal digits are represented in columns. The red color shows positive (shapley values), matching pixels in the image for feature importance.</p>
							<p>Blue color shows negative or detracting shapley values for pixels.</p>
							<p>More red in the image shows where there is a match and the particular pixels that matter.</p>
							<p>Visual explanation better than LIME but still only a visual representation</p>
						</aside>
					</section>

					<section>
						<h2>Confusion Matrix - One Versus Others</h2>
								<br>

								<table style="border: none;" class="realbig">
									<tr>
										<th style="border: none;"></th>
										<th style="width:25px; border: none;"></th>
										<th scope="row" colspan="4" style="background-color: lightgray; text-align: center;">Predicted<br>Classes</th>
									</tr>
								<tr>
									<th style="border: none;"></th>
									<th style="border: none;"></th>
									<th style="background-color: papayawhip; text-align: center;">a</th>
									<th style="background-color: papayawhip; text-align: center;">b</th>
									<th style="background-color: papayawhip; text-align: center;">c</th>
									<th style="background-color: papayawhip; text-align: center;">d</th>
								</tr>
								<tr>
									<th scope="col" rowspan="4" style="background-color: lightgray;">Actual<br>Classes</th>
									<th style="background-color: papayawhip;">a</th>
									<td style="background-color: lightblue;">TN</td>
									<td style="background-color: orange;">FP</td>
									<td style="background-color: lightblue;">TN</td>
									<td style="background-color: lightblue;">TN</td>
								</tr>
								<tr>
									<th style="background-color: papayawhip;">b</th>
									<td style="background-color: yellow;">FN</td>
									<td style="background-color: lightgreen;">TP</td>
									<td style="background-color: yellow;">FN</td>
									<td style="background-color: yellow;">FN</td>
								</tr>
								<tr>
									<th style="background-color: papayawhip;">c</th>
									<td style="background-color: lightblue;">TN</td>
									<td style="background-color: orange;">FP</td>
									<td style="background-color: lightblue;">TN</td>
									<td style="background-color: lightblue;">TN</td>
								</tr>
								<tr style="border-bottom: 2px solid black;">
									<th style="background-color: papayawhip;">d</th>
									<td style="background-color: lightblue;">TN</td>
									<td style="background-color: orange;">FP</td>
									<td style="background-color: lightblue;">TN</td>
									<td style="background-color: lightblue;">TN</td>
								</tr>
								</table>

								<br>
								<table class="mid">
									<tr>
										<th style="background-color: lightgray;">Legend</th>
									</tr>
									<tr>
										<td style="background-color: lightgreen;">True Positives (TP)</td>
									</tr>
									<tr>
										<td style="background-color: lightblue;">True Negatives (TN)</td>
									</tr>
									<tr>
										<td style="background-color: orange;">False Positives (FP)</td>
									</tr>
									<tr>
										<td style="background-color: yellow;">False Negatives (FN)</td>
									</tr>
								</table>

						<aside class="notes">
							<p>Confusion matrix is a way of capturing performance of a prediction it captures where a predictor gets confused as well as where it succeeds</p>
							<p>By performance I refer to how well it predicts</p>
							<p>The confusion matrix here has four classes a through d</p>
							<p>Counts are typically stored in the cells</p>
							<p>This particular confusion matrix is focused on class b and using one versus others approach</p>
							<p>True Positives are a correct result in predicting the b</p>
							<p>True Negatives are a correct result of predicting something other than b</p>
							<p>False Positives are an incorrect result of mistakenly predicting other classes as a b</p>
							<p>False Negatives are an incorrect result of predicting an actual b as something else</p>
							<p>Confusion matrix is often used in metrics to gauge performance of ML models. We also rely heavily on the confusion matrix in PBE</p>
						</aside>

					</section>

					<section>

						<section>
							<h1>Performance Metrics</h1>

							<div class="container">

								<div class="col" style="border-right:1px solid #000;height:900px">

									<br><br>

									<ul class="realbig">
										<li>Accuracy = $\frac{TP+TN}{TP+TN+FP+FN}$</li>
										<br>
										<li>Precision = $\frac{TP}{TP+FP}$</li>
										<br>
										<li>Recall = $\frac{TP}{TP+FN}$</li>
										<br>
										<li>Specificity = $\frac{TN}{TN+FP}$</li>
										<br>
										<li>False Discovery Rate (FDR) = $\frac{FP}{FP+TP}$</li>
									</ul>

									<!--
									<hr>

									<div class="smaller">
										<table  style="border: none;">
											<tr>
												<th style="border: none;"></th>
												<th style="width:25px; border: none;"></th>
												<th scope="row" colspan="4" style="background-color: lightgray; text-align: center;">Predicted<br>Classes</th>
											</tr>
										<tr>
											<th style="border: none;"></th>
											<th style="border: none;"></th>
											<th style="background-color: papayawhip; text-align: center;">a</th>
											<th style="background-color: papayawhip; text-align: center;">b</th>
											<th style="background-color: papayawhip; text-align: center;">c</th>
											<th style="background-color: papayawhip; text-align: center;">d</th>
										</tr>
										<tr>
											<th scope="col" rowspan="4" style="background-color: lightgray;">Actual<br>Classes</th>
											<th style="background-color: papayawhip;">a</th>
											<td style="background-color: lightblue;">TN</td>
											<td style="background-color: orange;">FP</td>
											<td style="background-color: lightblue;">TN</td>
											<td style="background-color: lightblue;">TN</td>
										</tr>
										<tr>
											<th style="background-color: papayawhip;">b</th>
											<td style="background-color: yellow;">FN</td>
											<td style="background-color: lightgreen;">TP</td>
											<td style="background-color: yellow;">FN</td>
											<td style="background-color: yellow;">FN</td>
										</tr>
										<tr>
											<th style="background-color: papayawhip;">c</th>
											<td style="background-color: lightblue;">TN</td>
											<td style="background-color: orange;">FP</td>
											<td style="background-color: lightblue;">TN</td>
											<td style="background-color: lightblue;">TN</td>
										</tr>
										<tr style="border-bottom: 2px solid black;">
											<th style="background-color: papayawhip;">d</th>
											<td style="background-color: lightblue;">TN</td>
											<td style="background-color: orange;">FP</td>
											<td style="background-color: lightblue;">TN</td>
											<td style="background-color: lightblue;">TN</td>
										</tr>
										</table>
										</div>
										-->

								</div>

								<div class="col">

									<br>

									<p class="realbig">Imbalance Ratio (IR)</p>

									<div class="realbig">
									\[
										IR = \frac{N_{maj}}{N_{min}}
									\]
									</div>

									<p class="realbig">If IR > 1 the data set is imbalanced</p>

									<hr>

									<ul class="realbig">
										<li>AUC</li>
										<p></p>
										<li>F1-Score</li>
										<p></p>
										<li>Cohen's Kappa</li>
										<p></p>
										<li>Matthew's Correlation Coefficient</li>
									</ul>

								</div>

							</div>

							<aside class="notes">
								<p>This slide depicts the metrics we used to gauge performance</p>
								<p>The metrics on the left are sensitive to imbalanced data</p>
								<p>False Discovery Rate or FDR give us a way of characterizing the predictions we get wrong and is useful in telling how a model fails in its predictions.</p>
								<p>Imbalance ratio tells us how well the data is balanced.  It is the cardinality of majority class over cardinality of minority class</p>
								<p>If the imbalance ratio is greater than 1, the data is said to be imbalanced and there are metrics that are resilient to data imbalance</p>
								<p>The metrics on the right are resilient to imbalanced data</p>
								<hr>
								<p>Accuracy represents correct results over all samples</p>
								<p>Precision tells us of all the predictions for a class, how many were correct.</p>
								<p>Recall aka sensitivity tells us how many items of an actual class were correctly identified</p>
								<p>Specificity indicates how well correct negative values are identified from all negative values.</p>
								<p>False Discovery Rate or FDR give us a way of characterizing the predictions we get wrong and is useful in telling how we have been shown to fail.</p>
								<p>AUC - receiver operating characteristic curve.  ROC is plot of TPR (recall) against FPR</p>
								<p>F-1 score is the harmonic mean of recall and precision. Harmonic mean reciprocal of arithmetic mean</p>
								<p>Cohen's Kappa was first used to characterize agreement between observers of a psychological experiment.</p>
								<p>Cohen's Kappa =  (probability of agreement - probability of random agreement) / (1 - probability of random agreement)</p>
								<p>MCC is Pearson's phi coefficient</p>
							</aside>
						</section>


					</section>



				<!--<section>  Property Based Method -->

				<section>

					<h1>Property-Based Explainable (PBE) Method</h1>

				</section>

				<section>
					<h2>PBE Method</h2>

					<hr>

					<div class="huge">
						<p><b>Intent:</b> Produce a system that can explain
						decisions to a user in plain terms by reasoning about the
						system's decisions in relation to explainable
						properties.</p>

						<p>
							<b>Explainable Property:</b>

								An attribute of an input sample that may
								differentiate between classes and provide rationale
								for a classification decision to a user.
						</p>
						<p>
							<b>Property Transform:</b>

							a property transformation is a function to modify an
							input sample to bring out an explainable property in the
							resulting output. A property transformation aims to
							highlight or exemplify explainable properties in the
							input.
						</p>
					</div>

				</section>

				<section>

					<h3>PBE Method - Steps</h3>

					<img src="./images/pbe-flow-lr.png">

					<aside class="notes">

					</aside>
				</section>

				<section>
					<h3>PBE Architecture - Goal of Method</h3>

					<img src="./images/pbe_arch_general.svg">

					<aside class="notes">
						<p>This is the PBE architecture.</p>
						<p>Composed from artifacts produced in following the PBE method.</p>
						<p>Each property and transform has an inference engine, trained model that provides an opinion</p>
						<p>We call these distinct opinions incident on the decision making process pre-decision flows.</p>
						<p>Decision making process selects among the opinions.</p>
						<p>Output of the system is decision, confidence, explanation, explainability, when the system has been shown to fail, alternatives.</p>
					</aside>

				</section>
				

				<section>
					<h2>PBE Properties and Transforms - MNIST</h2>
					<br>
					
					<div class="container">
						<div class="col">
						<table class="large">
							<tr>
								<th>Property</th>
								<th>Transform</th>
								<th>Image</th>
								<th>Trans.</th>
							</tr>
							<tr>
								<td>Stroke</td>
								<td>Skeleton</td>
								<td height="40"><img src="./images/mnist_prop_trans_examples/4-11.png" width="50" height="50"></td>
								<td height="40"><img src="./images/mnist_prop_trans_examples/4-11-skel.png" width="50" height="50"></td>
							</tr>
							<tr>
								<td>Circle</td>
								<td>Hough Circle</td>
								<td height="40"><img src="./images/mnist_prop_trans_examples/6-17.png" width="50" height="50"></td>
								<td height="40"><img src="./images/mnist_prop_trans_examples/6-17-circle.png" width="50" height="50"></td>
							</tr>
							<tr>
								<td>Circle</td>
								<td>Hough Ellipse</td>
								<td height="40"><img src="./images/mnist_prop_trans_examples/0-3.png" width="50" height="50"></td>
								<td height="40"><img src="./images/mnist_prop_trans_examples/0-3-ellipse.png" width="50" height="50"></td>
							</tr>
							<tr>
								<td>Circle</td>
								<td>Multiple Circle and Ellipse</td>
								<td height="40"><img src="./images/mnist_prop_trans_examples/8-4.png" width="50" height="50"></td>
								<td height="40"><img src="./images/mnist_prop_trans_examples/8-4-ellipse-circle.png" width="50" height="50"></td>
							</tr>
							<tr>
								<td>Crossings</td>
								<td>Intersection</td>
								<td height="40"><img src="./images/mnist_prop_trans_examples/4-2.png" width="50" height="50"></td>
								<td height="40"><img src="./images/mnist_prop_trans_examples/4-2-crossing.png" width="50" height="50"></td>
							</tr>
						</table>
						</div>

						<div class="col">
						<table class="large">
							<tr>
								<th>Property</th>
								<th>Transform</th>
								<th>Image</th>
								<th>Trans.</th>
							</tr>
							<tr>
								<td>Endpoints</td>
								<td>Endpoints</td>
								<td height="40"><img src="./images/mnist_prop_trans_examples/2-2.png" width="50" height="50"></td>
								<td height="40"><img src="./images/mnist_prop_trans_examples/2-2-endpoint.png" width="50" height="50"></td>
							</tr>
							<tr>
								<td>Enclosed Region</td>
								<td>Flood Fill</td>
								<td height="40"><img src="./images/mnist_prop_trans_examples/0-2.png" width="50" height="50"></td>
								<td height="40"><img src="./images/mnist_prop_trans_examples/0-2-fill.png" width="50" height="50"></td>
							</tr>
							<tr>
								<td>Enclosed Region</td>
								<td>Convex Hull</td>
								<td height="40"><img src="./images/mnist_prop_trans_examples/0-0-12.png" width="50" height="50"></td>
								<td height="40"><img src="./images/mnist_prop_trans_examples/0-0-12-ch.png" width="50" height="50"></td>
							</tr>
							<tr>
								<td>Line</td>
								<td>Hough Line</td>
								<td height="40"><img src="./images/mnist_prop_trans_examples/7-20.png" width="50" height="50"></td>
								<td height="40"><img src="./images/mnist_prop_trans_examples/7-20-line.png" width="50" height="50"></td>
							</tr>
							<tr>
								<td>Corner</td>
								<td>Harris Corner</td>
								<td height="40"><img src="./images/mnist_prop_trans_examples/3-18.png" width="50" height="50"></td>
								<td height="40"><img src="./images/mnist_prop_trans_examples/3-18-corner.png" width="50" height="50"></td>
							</tr>
						</table>
						</div>
					</div>

					<aside class="notes">
						<p>This slide details MNIST transform examples</p>
						<p>Table divided into two columns for better layout in slide.</p>
						<p>first column is the property name, second is transform.  Last two columns are the original input
							and finally th transformed input</p>
						<p>Several of the transforms are simple digital image processing techniques</p>
						<p>Stroke property, path followed by the writing implement, achieved by taking the morphological skeleton, one pixel wide
							connected representation</p>
						<p>A few transforms related to circles due to matching some digits - small circles like 6 and 9 , multiple circles like 8 - ellipse for zero</p>
						<p>Crossings/intersection which uses the skeleton and takes any points with more than 2 neighbors</p>
						<p>Endpoints which is also based on the skeleton and takes points with 1 neighbor.</p>
						<p>Enclosed regions which use 2 transforms flood fill and convex hull</p>
						<p>Lines in images via the hough line</p>
						<p>Inflection points or corners with the harris corner detection algorithm</p>
					</aside>

				</section>

				<section>
					<h2>Transform Training Data</h2>
					<br>
					<img src="./images/property-trans-training-db-dot.svg" height="800">
				</section>

				<section>
					<h2>Train ML Models</h2>
					<br>
					<img src="./images/property-ml-training-dot.svg" height="800">
				</section>

				<section>
					<h2>Build Knowledgebase</h2>
					<br>
					<img src="./images/property-ml-kb-dot.svg" height="800">
				</section>

				<section>
					<h2>Voting Scheme</h2>

					<ul class="REALBIG">
						<li>
							<b>Voting:</b>
							Selecting among potentially conflicting opinions from
							inference engines.
						</li>
						<p></p>
						<li>
							<b>Effectiveness:</b>
							Characterizes how well an inference engine performs.
							The effectiveness of an inference engine, $j$, to
							correctly recognize an item of class $c$ is
							expressed as $E(j,c)$.
						</li>
						
					</ul>

					<hr>

					<img src="./images/property-voter-dot.png">

					<aside class="notes">
						<p>Voting involves selection among potentially conflicting opinions from the flows</p>
						<p>Selecting among flow opinions is based on metrics gauging effectiveness of the</p>
						<p>A good choice of effectiveness metric depends on how balanced the data is. Good choices of effectiveness metrics are
							those resilient to data imbalance</p>
						<p>Effectiveness metrics can be calculated from data stored in the knowledgebase from processing the training data.</p>
						<p>Use a probabilistic voting scheme based on effectiveness</p>
					</aside>

				</section>

				<section>
					<h2>Voting Scheme - Continued</h2>
					<hr>
					<br>

					<p class="large">Weighted Effectiveness, $WE(c)$ for a class $c$ is the sum of effectiveness for all IEs, $j$, that voted for $c$</p>
						\[
						WE(c)=\sum_j E(j, c)
						\]
					
					<hr>
					
						<p class="large">Confidence, $Conf(c)$, for a class $c$ is the Weighted Effectiveness of $c$ over the sum of Weighted Effectiveness of all classes that were voted upon</p>
						\[
						Conf(c)=\frac{WE(c)}{\sum\limits_kWE(k)}
						\]

					<h4>Class $c$ with highest confidence wins</h4>

						<aside class="notes">
						<p>Weighted effectiveness for a class c is the sum of effectiveness of the inference engines that voted for c</p>
						<p>Confidence for a class c is the weighted effectiveness of c over the weighted effectiveness for all classes that received a vote</p>
						<p>The class with the greatest confidence wins the vote.</p>
						</aside>

				</section>

				<section>
					<h2>Explainability</h2>

					<ul class="realbig">
						<li>Some properties and transforms have lacking performance</li>
						<li>Addition of unexplainable inference to improve performance</li>
						<li>Need a means of quantifying explainability, $Ex(c)$, for a class $c$</li>
						<li>Each property transform, $j$, has a an explainbility metric $0 \le X_j \le 1$ </li>
					</ul>

					\[
					Ex(c)=\frac{\sum{E(j,c)X_j}}{\sum{E(j,c)}}
					\]

					<aside class="notes">
						<p>Some property transforms have mediocre results.</p>
						<p>An unexplainable component (no property no transform) can be added to the system to improve performance</p>
						<p>Explainability of a property and transform with associated inference engine  j is an assigned metric X_j based on relation to an explainable property.</p>
						<p>Explainability of a class c is the sum of product of effectiveness and explainability of the transform for the properties voting for c over the sum of all effectiveness for properties voting for c</p>
					</aside>
					
				</section>

				<section>

					<h2>Explanation Routine - XAI Block</h2>

					<ul class="realbig">
						<li>Assemble the textual rationale composed of</li>
						<li>The winning vote with confidence and explainability</li>
						<li>Present alternatives voted for with confidence and explainability</li>
						<li>Common failures based on historical FDR</li>
					</ul>

				</section>

				<!--</section>  Property Based Method -->

				<!--<section>-->

					<section>
						<h2>Property-Based Explainability Results</h2>
					</section>

					<section>
						<h2>Handwritten Character Datasets</h3>

						<hr>

						<p class="huge">Widely used for <b>BENCHMARKING</b> ML architectures</p>

						<ul class="huge">
							<li>
								MNIST - 70,000 decimal digit images<br>
								<img src="./images/mnist_samples/0-0.png" width="80"> <img src="./images/mnist_samples/1-0.png" width="80">
								<img src="./images/mnist_samples/2-0.png" width="80"> <img src="./images/mnist_samples/3-0.png" width="80">
								<img src="./images/mnist_samples/4-0.png" width="80"> <img src="./images/mnist_samples/5-0.png" width="80">
								<img src="./images/mnist_samples/6-0.png" width="80"> <img src="./images/mnist_samples/7-0.png" width="80">
								<img src="./images/mnist_samples/8-0.png" width="80"> <img src="./images/mnist_samples/9-0.png" width="80">

							</li>
							<li class="huge">
								EMNIST - Over 800,000 digits, uppercase and lowercase characters<br>
								<img src="./images/emnist_samples/10-0.png" width="80"> <img src="./images/emnist_samples/11-0.png" width="80">
								<img src="./images/emnist_samples/12-0.png" width="80"> <img src="./images/emnist_samples/13-0.png" width="80">
								<img src="./images/emnist_samples/14-0.png" width="80"> <img src="./images/emnist_samples/15-0.png" width="80">
								<img src="./images/emnist_samples/16-0.png" width="80"> <img src="./images/emnist_samples/17-0.png" width="80">
								<img src="./images/emnist_samples/18-0.png" width="80"> <img src="./images/emnist_samples/19-0.png" width="80"><br>
								<img src="./images/emnist_samples/36-0.png" width="80"> <img src="./images/emnist_samples/37-0.png" width="80">
								<img src="./images/emnist_samples/38-0.png" width="80"> <img src="./images/emnist_samples/39-0.png" width="80">
								<img src="./images/emnist_samples/40-0.png" width="80"> <img src="./images/emnist_samples/41-0.png" width="80">
								<img src="./images/emnist_samples/42-0.png" width="80"> <img src="./images/emnist_samples/43-0.png" width="80">
								<img src="./images/emnist_samples/44-0.png" width="80"> <img src="./images/emnist_samples/45-0.png" width="80">
							</li>
							<li>Dataset balanced among classes</li>
							<li>Images, therefore high dimensionality or many features</li>
						</ul>
						
						<aside class="notes">
							<p>Modified National Institute of Standards and Technology database</p>
							<p>Extended Modified National Institute of Standards and Technology database</p>
							<p>Best error rates in 2004 of ML on MNIST were around 0.4%</p>
							<p>Current best error rates on MNIST are about 0.2%</p>
						</aside>

					</section>

					<section>
						<h2>Property Based Architecture<br>MNIST Aggregate Results</h2>
						<hr>

						<div class="container">

						<div class="col" style="border-right:1px solid #000;height:500px">

						<h3>Accuracy</h3>

						<table class="large" style="border: none;">
							<tr>
								<td style="border: none;"></td>
								<th colspan="3" style="text-align: center;">Architecture</th>
							</tr>
							<tr>
								<th>ML Model Type</th>
								<th>1 Unexpl.</th>
								<th>10 Expl.</th>
								<th>10 Expl.<br>1 Unexpl.</th>
							</tr>
							<tr>
								<td>MLP</td>
								<td>98.3</td>
								<td>96.2</td>
								<td>97.9</td>
							</tr>
							<tr>
								<td>SVM</td>
								<td>97.9</td>
								<td>95.4</td>
								<td>97.3</td>
							</tr>
							<tr>
								<td>CNN</td>
								<td>99.4</td>
								<td>97.3</td>
								<td>98.7</td>
							</tr>
							<tr style="border-bottom: 2px solid black;">
								<td>Resnet50</td>
								<td>98.9</td>
								<td>97.6</td>
								<td>98.8</td>
							</tr>
							<!--style="border-bottom: 2px solid black;"-->
							</table> 

						</div>

						<div class="col">
						<h3>Average Explainability</h3>

						<table class="large" style="border: none;">
							<tr>
								<td style="border: none;"></td>
								<th colspan="3" style="text-align: center;">Architecture</th>
							</tr>
							<tr>
								<th>ML Model Type</th>
								<th>1 Unexpl.</th>
								<th>10 Expl.</th>
								<th>10 Expl.<br>1 Unexpl.</th>
							</tr>
							<tr>
								<td>MLP</td>
								<td>0.0</td>
								<td>100</td>
								<td>67.2</td>
							</tr>
							<tr>
								<td>SVM</td>
								<td>0.0</td>
								<td>100</td>
								<td>76.8</td>
							</tr>
							<tr>
								<td>CNN</td>
								<td>0.0</td>
								<td>100</td>
								<td>75.5</td>
							</tr>
							<tr style="border-bottom: 2px solid black;">
								<td>Resnet50</td>
								<td>0.0</td>
								<td>100</td>
								<td>69.9</td>
							</tr>
							<!--style="border-bottom: 2px solid black;"-->
							</table>

							</div>
							</div>

							<hr>

							<div class="container">
								<div class="col" style="border-right:1px solid #000;height:260px">
									<p class="mid">Unexplainable (Unexp.)</p>
									<img src="./images/unexp.svg" height="140">
								</div>
								<div class="col" style="border-right:1px solid #000;height:260px">
									<p class="mid">Explainable (Expl.)</p>
									<img src="./images/exp.svg" height="200">
								</div>
								<div class="col">
									<p class="mid">Explainable + Unexplainable</p>
									<img src="./images/exp-unexp.svg" height="200">
								</div>
							</div>

							<aside class="notes">
								<p>These tables show the aggregate performance of PBE on MNIST</p>
								<p>Left shows accuracy of different architectures in columns</p>
								<p>The architectures are depicted along the bottom in diagrams</p>
								<p>The first architecture is 1 ML model that is not explainable as a benchmark</p>
								<p>The second architecture shows 10 fully explainable flows</p>
								<p>The third has 10 explainable and 1 unexplainable flow</p>
								<p>In terms of accuracy, the explainable system performs the worst, a couple percentage points below benchmark</p>
								<p>Adding an unexplainable component we see gets us back near performance of the benchmark</p>
								<p>The table on the right shows average explainability for the winning class</p>
								<p>Benchark is not explainable.</p>
								<p>Fully explainable system is 100%</p>
								<p>Because the mix of explainable and unexplainable, explanability is diminshed.</p>
							</aside>

					</section>

					<section>
						<h2>MNIST Explainable Results: Digit <img src="./images/4_4_0.png" width="65" height="65"></h2>

						<table class="mid">
							<tr>
								<th rules="none" colspan="3"></th>
								<th colspan="3" style="text-align: center;">Effectiveness</th>
								<th colspan="3" style="text-align: center;">Explainability</th>
							</tr>
							<tr>
								<th>F<sub>j</sub></th>
								<th>Property</th>
								<th>Vote</th>
								<th>E(j,0)</th>
								<th>E(j,4)</th>
								<th>E(j,9)</th>
								<th>$Ex(0)$</th>
								<th>$Ex(4)$</th>
								<th>$Ex(9)$</th>
							</tr>
							<tr>
								<td>F<sub>1</sub></td>
								<td>Stroke</td>
								<td>4</td>
								<td></td>
								<td>1.0</td>
								<td></td>
								<td></td>
								<td>1.0</td>
								<td></td>
							</tr>
							<tr>
								<td>F<sub>2</sub></td>
								<td>Circle</td>
								<td>0</td>
								<td>0.039</td>
								<td></td>
								<td></td>
								<td>1.0</td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td>F<sub>3</sub></td>
								<td>Crossing</td>
								<td>0</td>
								<td>0.018</td>
								<td></td>
								<td></td>
								<td>1.0</td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td>F<sub>4</sub></td>
								<td>Ellipse</td>
								<td>0</td>
								<td>0.004</td>
								<td></td>
								<td></td>
								<td>1.0</td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td>F<sub>5</sub></td>
								<td>Ell-Cir</td>
								<td>0</td>
								<td>0.069</td>
								<td></td>
								<td></td>
								<td>1.0</td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td>F<sub>6</sub></td>
								<td>Endpoint</td>
								<td>4</td>
								<td></td>
								<td>0.974</td>
								<td></td>
								<td></td>
								<td>1.0</td>
								<td></td>
							</tr>
							<tr>
								<td>F<sub>7</sub></td>
								<td>Enc. Reg.</td>
								<td>0</td>
								<td>0.021</td>
								<td></td>
								<td></td>
								<td>1.0</td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td>F<sub>8</sub></td>
								<td>Line</td>
								<td>9</td>
								<td></td>
								<td></td>
								<td>0.496</td>
								<td></td>
								<td></td>
								<td>1.0</td>
							</tr>
							<tr>
								<td>F<sub>9</sub></td>
								<td>Con. Hull</td>
								<td>4</td>
								<td></td>
								<td>0.826</td>
								<td></td>
								<td></td>
								<td>1.0</td>
								<td></td>
							</tr>
							<tr>
								<td>F<sub>10</sub></td>
								<td>Corner</td>
								<td>4</td>
								<td></td>
								<td>0.538</td>
								<td></td>
								<td></td>
								<td>1.0</td>
								<td></td>
							</tr>
							<tr>
								<td>F<sub>11</sub></td>
								<td>Unexp.</td>
								<td>4</td>
								<td></td>
								<td>1.0</td>
								<td></td>
								<td></td>
								<td>0.0</td>
								<td></td>
							</tr>
							<tr>
								<td colspan="3" class="medium">$WE(c)$ / $\sum{E(j,c)X_j}$</td>
								<td>0.151</td>
								<td>4.337</td>
								<td>0.496</td>
								<td>0.151</td>
								<td>3.337</td>
								<td>0.496</td>
							</tr>
							<tr>
								<td colspan="3">Confidence/Expl</td>
								<td>3.03%</td>
								<td>87.0%</td>
								<td>9.96%</td>
								<td>100.0%</td>
								<td>76.9%</td>
								<td>100%</td>
							</tr>
						</table>

						<aside class="notes">
							<p>This table is an explainability matrix for a sample, the digit four a the top.</p>
							<p>We have columns indicating the flow, property transform and the vote of that property transform.</p>
							<p>There are votes for the digit four, zero and nine</p>
							<p>Next we show effectiveness. There will be three columns for effectiveness because of the three votes.</p>
							<p>Again effectiveness is the ability for the flow that voted to predict a particular class.  It is a metric in the knowledgebase</p>
							<p>Effectiveness of the votes for the digit four were relatively high compared to the low effectiveness for the zero</p>
							<p>Effectiveness for the nine vote was medium</p>
							<p>Effectiveness per class or column is summed to get a Weighted effectiveness</p>
							<p>Confidence is the weighted effectiveness of a class over weighted effectiveness of all classes voted for</p>
							<p>We see the four has the highest confidence and wins with 87% confidence</p>
							<p>Explainability is shown in the next three columns</p>
							<p>The explainability metric for each flow X_j is shown in the cells for the class the flow voted for</p>
							<p>We then calculate the effectiveness weighted effectiveness from taking the product of effectiveness and explainability</p>
							<p>The explainability of the answer for four is diminished because the unexplainable flow voted for it</p>
						</aside>
					</section>

					<section>
						<h2>PBE - Response for Digit <img src="./images/4_4_0.png" width="65" height="65"></h2>

						<ul class="realbig">
							<li>
								Confidence is high, 87%, for interpreting this
								character as a four due to the stroke, endpoint,
								convex hull, and corner properties.
								Explainability was 76.9%. The FDR shows when
								selecting a four, 1.9% of the time we are
								incorrect.  The most frequent mistakes are that
								the digit is a nine 0.9% and a seven 0.3% of the
								cases.
							</li>

						</ul>

					</section>

					<section>
						<h2>PBE - Alternatives for Digit <img src="./images/4_4_0.png" width="65" height="65"></h2>

						<ul class="realbig">
							<li>
								Confidence is low, 9.96%, for interpreting this
								character as a nine due to the line property.
								Explainability was 100%. The FDR shows when
								selecting a nine, 2.6% of the time we are
								incorrect.  The most frequent mistakes are that
								the digit is a four 1.4% of the time and an
								eight 0.5% of the cases.
							</li>
							<li>
								Confidence is low, 3.03% for interpreting this
								character as a zero due to the ellipse-circle,
								circle, fill, crossing, and ellipse properties.
								Explainability was 100%. he FDR shows when
								selecting a zero, 1.4% of the time we are
								incorrect. The most frequent mistake is that the
								digit is an eight 0.6% of the time.
							</li>
						</ul>
					</section>

					<section>
					<section>

						<h3>EMNIST Aggregate Results</h3>
						<hr>

						<div class="realbig">
						Unexplainable<br>

						<img src="./images/unexpl-emnist.png" height="350">

						<br>Explainable<br>

						<img src="./images/expl-emnist.png" height="350">

						</div>

					</section>


					<section>
						<h3>EMNIST Explainable Results: Character <img src="./images/test-C-1.png" width="65" height="65"></h3>

						<table class="mid">
							<tr>
								<th rules="none" colspan="3"></th>
								<th colspan="4">Effectiveness</th>
								<th colspan="4">Explainability</th>
							</tr>
							<tr>
								<th>F<sub>j</sub></th>
								<th>Property</th>
								<th>Vote</th>
								<th>E(j,C)</th>
								<th>E(j,T)</th>
								<th>E(j,U)</th>
								<th>E(j,X)</th>
								<th>$Ex(C)$</th>
								<th>$Ex(T)$</th>
								<th>$Ex(U)$</th>
								<th>$Ex(X)$</th>
							</tr>
							<tr>
								<td>F<sub>1</sub></td>
								<td>Stroke</td>
								<td>C</td>
								<td>0.964</td>
								<td></td>
								<td></td>
								<td></td>
								<td>1.0</td>
								<td></td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td>F<sub>2</sub></td>
								<td>Circle</td>
								<td>C</td>
								<td>0.114</td>
								<td></td>
								<td></td>
								<td></td>
								<td>1.0</td>
								<td></td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td>F<sub>3</sub></td>
								<td>Crossing</td>
								<td>C</td>
								<td>0.056</td>
								<td></td>
								<td></td>
								<td></td>
								<td>1.0</td>
								<td></td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td>F<sub>4</sub></td>
								<td>Ellipse</td>
								<td>T</td>
								<td></td>
								<td>0.009</td>
								<td></td>
								<td></td>
								<td></td>
								<td>1.0</td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td>F<sub>5</sub></td>
								<td>Ell-Cir</td>
								<td>C</td>
								<td>0.131</td>
								<td></td>
								<td></td>
								<td></td>
								<td>1.0</td>
								<td></td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td>F<sub>6</sub></td>
								<td>Endpoint</td>
								<td>C</td>
								<td>0.574</td>
								<td></td>
								<td></td>
								<td></td>
								<td>1.0</td>
								<td></td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td>F<sub>7</sub></td>
								<td>Enc. Reg.</td>
								<td>X</td>
								<td></td>
								<td></td>
								<td></td>
								<td>0.005</td>
								<td></td>
								<td></td>
								<td></td>
								<td>1.0</td>
							</tr>
							<tr>
								<td>F<sub>8</sub></td>
								<td>Line</td>
								<td>U</td>
								<td></td>
								<td></td>
								<td>0.244</td>
								<td></td>
								<td></td>
								<td></td>
								<td>1.0</td>
								<td></td>
							</tr>
							<tr>
								<td>F<sub>9</sub></td>
								<td>Con. Hull</td>
								<td>C</td>
								<td>0.603</td>
								<td></td>
								<td></td>
								<td></td>
								<td>1.0</td>
								<td></td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td>F<sub>10</sub></td>
								<td>Corner</td>
								<td>C</td>
								<td>0.369</td>
								<td></td>
								<td></td>
								<td></td>
								<td>1.0</td>
								<td></td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td>F<sub>11</sub></td>
								<td>Unexp.</td>
								<td>C</td>
								<td>0.989</td>
								<td></td>
								<td></td>
								<td></td>
								<td>0.0</td>
								<td></td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td colspan="3" class="medium">$WE(c)$ / $\sum{E(j,c)X_j}$</td>
								<td>3.801</td>
								<td>0.009</td>
								<td>0.244</td>
								<td>0.005</td>
								<td>2.812</td>
								<td>0.009</td>
								<td>0.244</td>
								<td>0.005</td>
							</tr>
							<tr>
								<td colspan="3">Confidence/Expl</td>
								<td>73.6%</td>
								<td>0.02%</td>
								<td>6.02%</td>
								<td>0.01%</td>
								<td>74.0%</td>
								<td>100%</td>
								<td>100%</td>
								<td>100%</td>
							</tr>
						</table>
					</section>
					</section>

					<section>

						<h2>Metrics and PBE</h2>

						<hr>

						<div class="container">

							<div class="col" style="border-right:1px solid #000;height:900px">

								<p class="realbig">
									$E_{PARS}$ as Effectiveness
								</p>

								<br><br>

								<p class="large">
									\[
										E_{PARS} = P \cdot ACC \cdot R \cdot S \\
									\]
								</p>

								<p class="large">
									$\frac{TN {\cdot} TP^3+TN^2 {\cdot} TP^2}{(TN{+}FP)(TP{+}FP)(TP{+}FN)(TP{+}TN{+}FP{+}FN)}$
								</p>

							</div>

							<div class="col">
								<p class="large">Performance of Metrics as Effectiveness on Handwriting</p>
								<img src="./images/metrics_table.png" height="800">
							</div>

						</div>

						<aside class="notes">
							<p>Experimenting with combinations of simple metrics, we came across the product of precision, accuracy, recall and specificity</p>
							<p>You see the expansion of EPARS here on the left.</p>
							<p>The right shows a table representing the performance aggregate accuracy of the PBE system using various effectiveness metrics.</p>
						</aside>


					</section>

				<!--</section>-->

				<section>
					<h1>Hardware Trojans</h1>
				</section>

				<section>
					<h2>Rare Event Hardware Trojan</h2>
					
					<hr>

					<img src="./images/trojan-model.svg" background="white" height="400">

					<aside class="notes">
						<p>Rare Event Confidentiality HW trojan in this diagram designed to leak sensitive information on primary output</p>
						<p>Dashed lines on left represent additional levels of logic gates</p>
						<p>To make the trojan difficult to detect, intentionally rare input patterns trigger the trojan payload</p>
						<p>Example for n inputs only 1 in 2^n input patterns trigger the trojan</p>
						<p>Trigger results in the mux leaking sensitive information on primary out</p>
						<p>We apply the methods to explainably detect HW trojans</p>
						<p>The problem we approach in this work is the static detection of HW trojans from gate level netlists using Trust-Hub trojan benchmark data</p>
					</aside>
				</section>

				<section data-visibility="hidden">
					<h2>Problem</h2>
					<ul class="realbig">
						<li>Static trojan detection using netlist features</li>
						<ol>
							<li>LGFi - Logic gate fanin</li>
							<li>FFi - Flip-flop input</li>
							<li>FFo - Flip-flop output</li>
							<li>PI - Primary input</li>
							<li>PO - Primary output</li>
						</ol>
						<li>Highly imbalanced dataset</li>
						<li>ML trained to make decisions</li>
						<li>Trust in the decisions is lacking - <b>Need Explanations</b></li>
					</ul>
					<aside class="notes">
						<p>The problem we approach in this work is the static detection of HW trojans from gate level netlists</p>
						<p>We do so using the following five features.</p>
						<p>LGFi - number of logic gate inputs two levels from a net</p>
						<p>FFi - the number of levels to the nearest flip-flop input</p>
						<p>FFo - the number of logic levels to the nearest flip-flop output</p>
						<p>PI - The logic level from a primary input</p>
						<p>PO - The logic level to a primary output</p>
						<p>Highly imbalanced dataset 250:1 (normal:trojan nets)</p>
						<p>Machine learning used to make decisions</p>
						<p>Trust in decision making is lacking.  We need explanations to establish trust</p>
					</aside>
				</section>

				<!--<section>-->
					
				<section data-visibility="hidden">
					<h3> Hardware Trojan Results</h3>
				</section>
			
				<section>
					<h2>Data Processing</h2>

					<hr>

					<div class="container">
						
						<div class="col">
							<img src="./images/data-processing.svg" background="white" height="700">
						</div>

						<div class="col" style="border-left:1px solid #000;height:760px">
							
							
							<p class="realbig">Dataset Characterization</p>
							<ul class="realbig">
								<li>15 Trust-hub netlists - 52k entries</li>
								<li>Five Features</li>
								<li>Two Classes: Trojan and Non-Trojan</li>
								<li>Highly Imbalanced data</li>
								<li>Trojan: Non-Trojan - 1:250</li>
								<li>Many Duplicates</li>
							</ul>
							<hr>
							<p class="realbig">Training and Test</p>
							<ul class="realbig">
								
								<li>80% used for training</li>
								<li>20% used for test</li>
							</ul>
						</div>

					</div>
					<aside class="notes">
						<p>Diagram depicts the flow of data processing from the verilog netlists</p>
						<p>Circuitgraph is used to parse the netlists</p>
						<p>A directed graph is constructed</p>
						<p>features are extracted</p>
						<p>Characterizing the data...</p>
						<p>Processed 15 of the trust-hub netlists to gather 52,000 samples representing nets in the netlist</p>
						<p>It has only five integer features so very dense in feature space.  Because it is dense there are many duplicates</p>
						<p>Data is highly imbalanced with a 1:250 ratio of trojan to non</p>
						<p>A random 80% used for training and 20% used to test</p>
					</aside>
				</section>

				<section>
					<h2>PBE Architecture - Trojans</h2>

					<div class="r-stack">

						<img
						class="fragment fade-out"
						data-fragment-index="0"
						src="./images/general-property-based-xai-arch.svg" background="white" height="700"/>

						<img
						class="fragment current-visible"
						data-fragment-index="0"
						src="./images/property-based-xai-arch.svg" background="white" height="600"/>

					</div>

					<p class="mid">Property = grouping of features</p>

					<aside class="notes">
						<p>Applying the property based method to five hardware trojan features, immediately we were faced with the problem of what a meaningful property was</p>
						<p>We tried to overcome the problem with using combinations of features</p>
						<p>This diagram depicts a general property based explainable architecture for a low dimensionality feature space</p>
						<p>Property is a grouping of features that can help explain decision</p> 
						<p>First phase is where combination property transforms of the features occurs</p>
						<p>A particular implementation of the architecture for 5 properties is depicted.  Note 31 properties the combinations of five features.</p>
					</aside>
				</section>

				<section>
					<section>
						<h2>PBE Example</h2>
						
						<p class="realbig">Sample</p>

						<img src="./images/example.png" height="150">

						<hr>

						<p class="realbig">Output</p>

						<img src="./images/property-example.png" height="300">

						
						<aside class="notes">
							<p>An example from the test set is depicted in this slide</p>
							<p>The particular values for the 5 features are depicted at the top</p>
							<p>The sample is a trojan shown in the last column and value of 1</p>
							<p>Output of the PBE system is depicted in the bottom.</p>
							<p>A trojan was predicted with 99.6% confidence</p>
							<p>The 15 properties contributing to the decision are listed in descending order of weight</p>
							<p>Note the properties are high property number 15 and above.</p>
							<p>Exlainability is low at 41%  We will see why from the next slide.</p>
						</aside>
					</section>

					<section>
						<h2>Properties</h2>
						
						
						<img src="./images/properties.png" height="800">

						
						<aside class="notes">
							<p>This table shows the 31 properties in the system and associated features</p>
							<p>Identifier in the first column, features in second explainability in third</p>
							<p>We argue that a property with few features is highly explainable and therefore has a high explability value</p>
							<p>While many or all features have very low explainability</p>
							<p>The explainability of 41% from the last slide is a result of combining properties with high feature counts and low explainability in the decision</p>
						</aside>
					</section>

				</section>


				<!--<section>  Case Based Method -->

				<section>

					<h1>Case-Based Explainable (CBE) Method</h1>

				</section>

				<section>
					<h2>CBE Method</h2>

					<hr>

					<div class="realbig">
						<p>
							<b>Intent:</b> Produce a system that can explain
						decisions to a user by providing evidence about like training cases.</p>

						<p>
							<b>Inspiration:</b> Work by Caruana et al. <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC2232607/">Case-based explanation of non-case-based learning methods</a>.
							In providing an answer
						</p>

						<p>
							Consider training samples as cases. Similar cases that the model was trained on should support a decision.
						</p>
						<p>
							Not explaining the model behavior but what was used to train the model that is like an input.
						</p>

					</div>

				</section>


				<section>
				<section>

					<h3>CBE Method - Steps</h3>

					<br><br>

					<img src="./images/cbe-flow-lr.svg">

				</section>

				<section data-visibility="hidden">

					<h2>CBE - Steps Detail</h2>

					<div class="container">

						<div class="col" style="border-right:1px solid #000;height:300px">

							<h7>Train ML Model</h7>

							<br>

							<img src="./images/case-train-ml-dot.svg">

						</div>

						<div class="col">

							<h7>Training Index</h7>

							<br>

							<img src="./images/case-training-index.svg">

						</div>

					</div>

					<hr>
						<h7>Query Scheme</h7>

						<img src="./images/case-query-routine.svg">

				</section>
				</section>

				<section>

					<h3>Explanation Routine</h3>

					<br>

					<img src="./images/case-explanation.svg" height="300">

					<hr>

					<h5> Weight of Neighbors and Correspondence</h5>
					
					<div class="large">

						<p>
							$WN(c) = \sum_{i=1}^{c_i \in k} \frac{bf(c)}{(d_i+1.0)^2}$
						</p>
						<p></p>
						<p>
							$Corr(c) = \frac{WN(c)}{\sum_{j=1}^{c_j \in k}{WN(c_j)}}$
						</p>

					</div>

					<aside class="notes">
						<p>This slide shows details of the explanation routine</p>
						<p>Inputs of K neighbors retrieved from the query scheme, application input, and the decision from the ML model come in from the left.</p>
						<p>The output at the left is the decision from the ML model, the correspondence and neighbor data as justification</p>
						<p>The correspondence is how well the neighbor data agrees with the answer.</p>
						<p>Weight of neighbors for a class c is calculated by taking the balance factor, to overcome the imbalance of the data, over the inverse square of distance.</p>
						<p>Correspondence for a class c is then the weght g neighbors for the class c over the weight of neighbors for all classes voted on.</p>
					</aside>

				</section>

				<section>

					<h3>CBE Architecture - Handwriting Results</h3>

					<br><br>

					<img src="./images/cbe-arch.svg" height="600">

				</section>

				<section>

					<h2>CBE Architecture - Results for Digit <img src="./images/4_4_0.png" width="65" height="65"></h2>

					<div class="container">

						<div class="col" style="border-right:1px solid #000;height:660px">
							<img src="./images/knn_case_based_mnist_example.png" height="600">
						</div>

						<div class="col">
							<br>
							<img src="./images/case_based_mnist_ex1_knn.png">
						</div>

					</div>

					<hr>

					<p>SVM Prediction: four </p>
					
					<p>Correspondence = 92.3%</p>

					<p>Alternatives: nine with 7.7% correspondence</p> 

				</section>

				<!--</section>  Case Based Method -->
				
					<section>
						<h4>CBE Architecture - Hardware Trojan Results</h4>
						<img src="./images/case-based-xai-arch.svg" background="white" height="500">
						<aside class="notes">
							<p></p>
						</aside>
					</section>

					<section>
						<h3>CBE Example</h3>
						
						<p class="realbig">Sample</p>

						<img src="./images/example.png" height="120">

						<hr>

						<p class="realbig">Output</p>

						<!--<div class="container">

							<div class="col" width="100"> -->
							<p class="realbig">SVM - Trojan</p>
							<!--</div> -->

							<!--<div class="col"> -->
							<img src="./images/case-example.png" height="400">
							<!--</div> -->

						<!--</div> -->

						
						<aside class="notes">
							<p>This slide depicts the same test sample we saw earlier.</p>
							<p>The inference engine recognized as a trojan.</p>
							<p>The output of the case based system is below</p>
							<p>Four neighboring groups were extracted and are listed by proximity, euclidean distance</p>
							<p>Distance is the first column, feature values of the group is next, ratio of trojan "t" to non-trojan "n" is shown</p>
							<p>The next two columns are trojan weight and non-trojan weight</p>
							<p>A balancing factor is used to overcome the data imbalance</p>
							<p>In addition to this information, the particular cases from training can be presented with their original context.</p>
						</aside>
					</section>
				<!--</section>-->


				<section>
					<h1>Conclusion</h1>

					<ul class="huge">
						<li>Explainable properties are difficult to elicit from low dimensional space</li>
						<li>Marginal explainability in property-based architecture</li>
						<li>Much more involved to implement the property based method</li>
						<li>Case-based architecture had 94.7% correspondence with inference engine</li>
						<li>Case-based outperformed the property-based architecture on handwriting and Trojans</li>
						<li>Four conference papers published</li>
					</ul>

					<aside class="notes">
						<p>Using only five features made it hard to extract explainable properties.  Explainable properties better suited for</p>
						<p>Marginal explainability - low explainability metrics in property based architecture due to large number of features in property</p>
						<p>Property based method takes much more effort and time to implement.</p>
						<p>Case-based architecture agreed with the SVM inference engine a very high percentage of time</p>
						<p>Cases and references gave compelling rationale for decisions.  Better than combinations of features.</p>
						<p>Four conference papers published</p>
					</aside>
					
				</section>

				<section>
					<h1>Conclusion - Continued</h1>

					<h3><a href="/#/4">Important User Questions Driving AI</a>:</h3>
					<br>


					<ul class="realbig">
						<li><a href="#/33">Why did you do that?</a></li>
						<li><a href="#/33">Why not something else?</a></li>
						<li><a href="#/34">How confident are you?</a></li>
						<li><a href="#/35">What else did you consider?</a></li>
						<li><a href="#/33">Are there alternatives?</a></li>
						<li><a href="#/34">When do you fail?</a></li>
					</ul>

					<p class="realbig">
					We successfully addressed these questions with evidence in the links above.
					</p>

					<aside class="notes">
						<p>Recall the important questions driving the need for XAI that XAI should answer...</p>
						<p>How did these methods and architectures answer the questions?</p>
					</aside>
					
				</section>

				<section>
					<h2>Future Work</h2>

					<ul class="realbig">
						<li>More applications for the methods</li>
						<li>Generalizing the property based method</li>
						<li>Scaling the case-based method to larger datasets</li>
						<li>Expanding the explainable interface for user
						questions/interrogation.<br>Large Language Models on the
						knowledgebase or training index</li>
					</ul>

					<aside class="notes">
						<p>Seek more applications to utilize the methods on</p>
						<p>Generalize the PBE using a pool of general properties and digital image processing techniques</p>
						<p>Use other feature extration techniques to generalize PBE</p>
						<p>Try the case based system on larger datasets look to scale the efficienc y of KNN retrieval</p>
						<p>Work on the explainable interface to provide the ability to ask questions uing LLM</p>
					</aside>
				</section>

				<section></section>

			</div>
		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script src="plugin/math/math.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				width: 1920,
				height: 1080,
				//width: 1280,
				//height: 720,
				//width: 1440,
				//height: 900,
				hash: true,

				//Laser pointer
				notes_pointer: {
					pointer: {
						size: 15,  // in pixels (scaled like the rest of reveal.js)
						color: 'rgba(255, 0, 0, 0.8)',  // something valid for css background-color
						key: 'A'
					}
				},

				dependencies: [
					{src: 'plugins/reveal.js-notes-pointer/notes-pointer.js', async: true}
				],

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath.KaTeX ],

				slideNumber: true

			});
		</script>


		<!--
			header footer
			https://stackoverflow.com/questions/34706859/set-header-and-footer-reveal-js-presentation
		-->

		<style type="text/css">
			/* 1. Style header/footer <div> so they are positioned as desired. */
			#header-left {
				position: absolute;
				top: 0%;
				left: 2%;
			}
			#header-right {
				position: absolute;
				top: 3%;
				right: 2%;
			}
			#footer-left {
				position: absolute;
				bottom: 0%;
				left: 0%;
			}
		</style>
		
		 
		<div id="hidden" style="display:none;">
			<div id="header">
				<div id="header-left"><img src="./images/CWRU-seal.jpg" width="150" height="137"></div>

				<!-- style="padding:0px; display: block; line-height: 0px; font-size: 0px; border:0px;" -->
				

			</div>
		</div>

		
		
		<script src="https://code.jquery.com/jquery-2.2.4.min.js"></script>
		<script type="text/javascript">
			// 3. On Reveal.js ready event, copy header/footer <div> into each `.slide-background` <div>
			var header = $('#header').html();
			if ( window.location.search.match( /print-pdf/gi ) ) {
				Reveal.addEventListener( 'ready', function( event ) {
					$('.slide-background').append(header);
				});
			}
			else {
				$('div.reveal').append(header);
		   }
		</script>

	</body>
</html>
